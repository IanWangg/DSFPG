{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Walker-Walk-Backward.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNF7EWaR2Pkp4e6zEcSlDTI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IanWangg/DSFPG/blob/master/Walker_Walk_Backward.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEXUCDZxj6Ve",
        "outputId": "068b3395-4d90-4bac-8a32-408ed8dbba68"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "%cd gdrive/My Drive/Workplace\n",
        "\n",
        "!git clone https://github.com/benelot/pybullet-gym.git\n",
        "\n",
        "%cd pybullet-gym/\n",
        "\n",
        "!pip install -e ."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/Workplace\n",
            "fatal: destination path 'pybullet-gym' already exists and is not an empty directory.\n",
            "/content/gdrive/My Drive/Workplace/pybullet-gym\n",
            "Obtaining file:///content/gdrive/My%20Drive/Workplace/pybullet-gym\n",
            "Collecting pybullet>=1.7.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/6d/60b97ffc579db665bdd87f2cb47fe1215ae770fbbc1add84ebf36ddca63b/pybullet-3.1.7.tar.gz (79.0MB)\n",
            "\u001b[K     |████████████████████████████████| 79.0MB 34kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pybullet\n",
            "  Building wheel for pybullet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pybullet: filename=pybullet-3.1.7-cp37-cp37m-linux_x86_64.whl size=89750721 sha256=675e5ac99d56f7a4a18af3930d41b13da73577d63e5abab3c30dbedd4abcc882\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/56/e6/fce8276a2f30165f7ac31089bb72f390fa16b87328651e1a5a\n",
            "Successfully built pybullet\n",
            "Installing collected packages: pybullet, pybulletgym\n",
            "  Running setup.py develop for pybulletgym\n",
            "Successfully installed pybullet-3.1.7 pybulletgym\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbK-RNiK4n_v",
        "outputId": "c8e9d015-f1cf-4031-dd42-549f79658a80"
      },
      "source": [
        "import gym\n",
        "import pybulletgym\n",
        "env = gym.make('Walker2DMuJoCoEnv-v0')\n",
        "env.reset().shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WalkerBase::__init__\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdoR5fugb9gK"
      },
      "source": [
        "# Define the agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39tSaJ0q7LRz",
        "cellView": "code"
      },
      "source": [
        "#@title\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import copy\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class ReplayBuffer(object):\n",
        "    def __init__(self, state_dim, action_dim, max_size=int(1e6)):\n",
        "        self.max_size = max_size\n",
        "        self.ptr = 0\n",
        "        self.size = 0\n",
        "\n",
        "        self.start_ptr = 0\n",
        "        self.start_size = 0\n",
        "\n",
        "        self.state = np.zeros((max_size, state_dim))\n",
        "        self.action = np.zeros((max_size, action_dim))\n",
        "        self.next_state = np.zeros((max_size, state_dim))\n",
        "        self.reward = np.zeros((max_size, 1))\n",
        "        self.not_done = np.zeros((max_size, 1))\n",
        "\n",
        "        self.start_state = np.zeros((max_size, state_dim))\n",
        "\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    def add(self, state, action, next_state, reward, done):\n",
        "        self.state[self.ptr] = state\n",
        "        self.action[self.ptr] = action\n",
        "        self.next_state[self.ptr] = next_state\n",
        "        self.reward[self.ptr] = reward\n",
        "        self.not_done[self.ptr] = 1. - done\n",
        "\n",
        "        self.ptr = (self.ptr + 1) % self.max_size\n",
        "        self.size = min(self.size + 1, self.max_size)\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        ind = np.random.randint(self.size, size=batch_size)\n",
        "\n",
        "        return (\n",
        "            torch.FloatTensor(self.state[ind]).to(self.device),\n",
        "            torch.FloatTensor(self.action[ind]).to(self.device),\n",
        "            torch.FloatTensor(self.next_state[ind]).to(self.device),\n",
        "            torch.FloatTensor(self.reward[ind]).to(self.device),\n",
        "            torch.FloatTensor(self.not_done[ind]).to(self.device)\n",
        "        )\n",
        "\n",
        "\n",
        "class Encoder_Decoder(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim):\n",
        "        super(Encoder_Decoder, self).__init__()\n",
        "\n",
        "        self.e1 = nn.Linear(state_dim + action_dim, 256)\n",
        "        self.e2 = nn.Linear(256, 256)\n",
        "\n",
        "        self.r1 = nn.Linear(256, 1, bias=False)\n",
        "\n",
        "        self.a1 = nn.Linear(256, 256)\n",
        "        self.a2 = nn.Linear(256, action_dim)\n",
        "\n",
        "        self.d1 = nn.Linear(256, 256)\n",
        "        self.d2 = nn.Linear(256, state_dim)\n",
        "\n",
        "\n",
        "    def forward(self, state, action):\n",
        "        l = F.relu(self.e1(torch.cat([state, action], 1)))\n",
        "        l = F.relu(self.e2(l))\n",
        "\n",
        "        r = self.r1(l)\n",
        "\n",
        "        d = F.relu(self.d1(l))\n",
        "        ns = self.d2(d)\n",
        "\n",
        "        d = F.relu(self.a1(l))\n",
        "        a = self.a2(d)\n",
        "\n",
        "        return ns, r, a, l\n",
        "\n",
        "    def latent(self, state, action):\n",
        "        l = F.relu(self.e1(torch.cat([state, action], 1)))\n",
        "        l = F.relu(self.e2(l))\n",
        "        return l\n",
        "\n",
        "\n",
        "class Critic(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim):\n",
        "        super(Critic, self).__init__()\n",
        "\n",
        "        self.l1 = nn.Linear(state_dim + action_dim, 256)\n",
        "        self.l2 = nn.Linear(256, 256)\n",
        "        self.l3 = nn.Linear(256, 256)\n",
        "\n",
        "    def forward(self, state, action):\n",
        "        q1 = F.relu(self.l1(torch.cat([state, action], 1)))\n",
        "        q1 = F.relu(self.l2(q1))\n",
        "        return self.l3(q1)\n",
        "  \n",
        "\n",
        "class Actor(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim, max_action):\n",
        "        super(Actor, self).__init__()\n",
        "\n",
        "        self.l1 = nn.Linear(state_dim, 256)\n",
        "        self.l2 = nn.Linear(256, 256)\n",
        "        self.l3 = nn.Linear(256, action_dim)\n",
        "        \n",
        "        self.max_action = max_action\n",
        "\n",
        "    def forward(self, state):\n",
        "        state = torch.tensor(state).to(device)\n",
        "        a = F.relu(self.l1(state))\n",
        "        a = F.relu(self.l2(a))\n",
        "        return self.max_action * torch.tanh(self.l3(a))\n",
        "\n",
        "\n",
        "class DSFPG(object):\n",
        "    def __init__(\n",
        "        self,\n",
        "        state_dim,\n",
        "        action_dim,\n",
        "        max_action,\n",
        "        max_step_before_learning,\n",
        "        buffer_size=int(1e6),\n",
        "        discount=0.99,\n",
        "        tau=0.005\n",
        "    ):\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        self.encoder_decoder = Encoder_Decoder(state_dim, action_dim).to(device)\n",
        "        self.ed_optimizer = torch.optim.Adam(self.encoder_decoder.parameters(), lr=3e-4)\n",
        "\n",
        "        self.actor = Actor(state_dim, action_dim, max_action).to(device)\n",
        "        self.actor_target = copy.deepcopy(self.actor)\n",
        "        self.actor_optimizer = torch.optim.Adam(self.actor.parameters(), lr=3e-4)\n",
        "\n",
        "        self.critic = Critic(state_dim, action_dim).to(device)\n",
        "        self.critic_target = copy.deepcopy(self.critic)\n",
        "        self.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr=3e-4)\n",
        "\n",
        "        # self.W = torch.ones(1, 256, requires_grad=True, device=device)\n",
        "        self.W = nn.Linear(256, 1)\n",
        "        # self.W_optimizer = torch.optim.Adam([self.W], lr=3e-4)\n",
        "        self.W_optimizer = torch.optim.Adam(self.W.parameters(), lr=3e-4)\n",
        "\n",
        "        self.discount = discount\n",
        "        self.tau = tau\n",
        "        self.max_step_before_learning = max_step_before_learning\n",
        "\n",
        "        self.total_it = 0\n",
        "\n",
        "        self.max_action = max_action\n",
        "\n",
        "        self.replay = ReplayBuffer(state_dim, action_dim, buffer_size)\n",
        "\n",
        "\n",
        "    def train_encoder_decoder(self, state, action, next_state, reward, done, batch_size=256):\n",
        "        self.replay.add(state, action, next_state, reward, done)\n",
        "\n",
        "        if self.replay.size > self.max_step_before_learning:\n",
        "            state, action, next_state, reward, not_done = self.replay.sample(batch_size)\n",
        "\n",
        "            recons_next, recons_reward, recons_action, lat = self.encoder_decoder(state, action)\n",
        "            ed_loss = F.mse_loss(recons_next, next_state) + 0.1 * F.mse_loss(recons_reward, reward) + F.mse_loss(recons_action, action)\n",
        "\n",
        "            self.ed_optimizer.zero_grad()\n",
        "            ed_loss.backward()\n",
        "            self.ed_optimizer.step()\n",
        "\n",
        "\n",
        "    def train_SR(self, state, action, next_state, reward, done, batch_size=256):\n",
        "        self.replay.add(state, action, next_state, reward, done)\n",
        "\n",
        "        if self.replay.size > self.max_step_before_learning:\n",
        "            state, action, next_state, reward, not_done = self.replay.sample(batch_size)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                next_action = self.actor_target(next_state)\n",
        "                # add randomness to the next action, this should be removed if the result is not idea \n",
        "                next_action = (next_action + torch.randn_like(next_action) * self.max_action * 0.1).clamp(-self.max_action, self.max_action)\n",
        "\n",
        "                latent = self.encoder_decoder.latent(state, action)\n",
        "                target_Q = latent + self.discount * not_done * self.critic_target(next_state, next_action)\n",
        "\n",
        "            current_Q = self.critic(state, action)\n",
        "            critic_loss = F.mse_loss(current_Q, target_Q)\n",
        "\n",
        "            self.critic_optimizer.zero_grad()\n",
        "            critic_loss.backward()\n",
        "            self.critic_optimizer.step()\n",
        "\n",
        "            for param, target_param in zip(self.critic.parameters(), self.critic_target.parameters()):\n",
        "                target_param.data.copy_(self.tau * param.data + (1 - self.tau) * target_param.data)\n",
        "\n",
        "\n",
        "    def train_w(self, state, action, next_state, reward, done, batch_size=256):\n",
        "        self.replay.add(state, action, next_state, reward, done)\n",
        "\n",
        "        if self.replay.size > self.max_step_before_learning:\n",
        "            state, action, next_state, reward, not_done = self.replay.sample(batch_size)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                latent = self.encoder_decoder.latent(state, action)\n",
        "            \n",
        "            reward_estimate = self.W(latent)\n",
        "            W_loss = F.mse_loss(reward_estimate, reward)\n",
        "\n",
        "            self.W_optimizer.zero_grad()\n",
        "            W_loss.backward()\n",
        "            self.W_optimizer.step()\n",
        "\n",
        "    def train_actor(self, state, action, next_state, reward, done, batch_size=256):\n",
        "        self.replay.add(state, action, next_state, reward, done)\n",
        "\n",
        "        if self.replay.size > self.max_step_before_learning:\n",
        "            state, action, next_state, reward, not_done = self.replay.sample(batch_size)\n",
        "\n",
        "            # actor_loss = -(self.critic(state, self.actor(state)) * self.W).mean()\n",
        "            actor_loss = -self.W(self.critic(state, self.actor(state))).mean()\n",
        "\n",
        "            self.actor_optimizer.zero_grad()\n",
        "            actor_loss.backward()\n",
        "            self.actor_optimizer.step()\n",
        "\n",
        "    def select_action(self, state):\n",
        "        with torch.no_grad():\n",
        "            action = self.actor(state)\n",
        "        return action\n",
        "\n",
        "    def train(self, state, action, next_state, reward, done):\n",
        "        self.train_encoder_decoder(state, action, next_state, reward, done)\n",
        "        self.train_SR(state, action, next_state, reward, done)\n",
        "        self.train_w(state, action, next_state, reward, done)\n",
        "        self.train_actor(state, action, next_state, reward, done)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yH9b8BoTTnYF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxxdT3WW7MBB"
      },
      "source": [
        "# Use PyBullet Built-in Locomotion Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92SSpcannBzw"
      },
      "source": [
        "from tqdm import trange\n",
        "import gym\n",
        "import pybulletgym\n",
        "\n",
        "def train_agent(agent_func, \n",
        "                env_name, # this should be an env object\n",
        "                runs=1,\n",
        "                max_steps=int(1e6),\n",
        "                max_step_before_learning=int(1e4)\n",
        "                ):\n",
        "    returns_timing = []\n",
        "    returns_value = []\n",
        "    agents = []\n",
        "    env = gym.make(env_name)\n",
        "    state_dim = env.observation_space.shape[0]\n",
        "    action_dim = env.action_space.shape[0]\n",
        "    max_action = float(env.action_space.high[0])\n",
        "    \n",
        "    for run in trange(runs, desc='runs'):\n",
        "        env.seed(run + 100)\n",
        "        total_steps = 0\n",
        "        done = True\n",
        "        # each element in returns array should be of shape [episodic_return, steps]\n",
        "        # if an episode is not over, episodic_return is 0\n",
        "        rewards = []\n",
        "        episodic_return = 0\n",
        "        agent = agent_func(state_dim=state_dim,\n",
        "                            action_dim=action_dim,\n",
        "                            max_action=max_action,\n",
        "                            max_step_before_learning=max_step_before_learning,\n",
        "                            buffer_size=max_steps)\n",
        "\n",
        "        while total_steps < max_steps:\n",
        "            if done:\n",
        "                print(f'Steps : {total_steps}, Episodic_return : {episodic_return}')\n",
        "                state = env.reset()\n",
        "                rewards.append([total_steps, episodic_return])\n",
        "                episodic_return = 0\n",
        "\n",
        "            total_steps += 1\n",
        "            action = agent.select_action(state)\n",
        "            next_state, reward, done, info = env.step(action)\n",
        "            agent.train(state, action, next_state, reward, done)\n",
        "            episodic_return += reward\n",
        "        \n",
        "        returns_timing.append(rewards[:, 0])\n",
        "        returns_timing.append(rewards[:, 1])\n",
        "        agents.append(agents)\n",
        "\n",
        "        filename = f'./state_dict/{agent_func.__name__}-{env_name}-{random_seed}.pt'\n",
        "        torch.save(agent.state_dict(), filename)\n",
        "    \n",
        "    return agents, returns_timing, returns_value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XteuKDI3xCFm",
        "outputId": "04e29ccf-dd50-4c83-d4e9-0d601dc1b2b3"
      },
      "source": [
        "agents, t, r = train_agent(agent_func=DSFPG,\n",
        "                           env_name='Walker2DMuJoCoEnv-v0')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "runs:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WalkerBase::__init__\n",
            "Steps : 0, Episodic_return : 0\n",
            "Steps : 13, Episodic_return : 9.623677253723145\n",
            "Steps : 27, Episodic_return : 9.697988510131836\n",
            "Steps : 38, Episodic_return : 1.1944817304611206\n",
            "Steps : 48, Episodic_return : 0.6268541812896729\n",
            "Steps : 60, Episodic_return : 8.471673965454102\n",
            "Steps : 73, Episodic_return : 8.472336769104004\n",
            "Steps : 89, Episodic_return : 10.730151176452637\n",
            "Steps : 102, Episodic_return : 7.555524826049805\n",
            "Steps : 116, Episodic_return : 10.27228832244873\n",
            "Steps : 131, Episodic_return : 9.074901580810547\n",
            "Steps : 145, Episodic_return : 9.265048027038574\n",
            "Steps : 160, Episodic_return : 12.156982421875\n",
            "Steps : 174, Episodic_return : 9.893916130065918\n",
            "Steps : 188, Episodic_return : 9.501594543457031\n",
            "Steps : 202, Episodic_return : 8.993680953979492\n",
            "Steps : 217, Episodic_return : 9.950523376464844\n",
            "Steps : 231, Episodic_return : 11.406591415405273\n",
            "Steps : 245, Episodic_return : 9.380926132202148\n",
            "Steps : 258, Episodic_return : 9.004058837890625\n",
            "Steps : 270, Episodic_return : 4.108003616333008\n",
            "Steps : 278, Episodic_return : -1.3647816181182861\n",
            "Steps : 287, Episodic_return : -0.7109068632125854\n",
            "Steps : 298, Episodic_return : 5.801429748535156\n",
            "Steps : 316, Episodic_return : 13.792783737182617\n",
            "Steps : 324, Episodic_return : 4.581291675567627\n",
            "Steps : 338, Episodic_return : 9.996466636657715\n",
            "Steps : 353, Episodic_return : 11.048347473144531\n",
            "Steps : 359, Episodic_return : -1.1842966079711914\n",
            "Steps : 374, Episodic_return : 11.479608535766602\n",
            "Steps : 390, Episodic_return : 9.563267707824707\n",
            "Steps : 406, Episodic_return : 10.427074432373047\n",
            "Steps : 419, Episodic_return : 9.519906997680664\n",
            "Steps : 435, Episodic_return : 9.700572967529297\n",
            "Steps : 449, Episodic_return : 10.490877151489258\n",
            "Steps : 464, Episodic_return : 10.848675727844238\n",
            "Steps : 478, Episodic_return : 9.20602798461914\n",
            "Steps : 489, Episodic_return : 8.528520584106445\n",
            "Steps : 503, Episodic_return : 11.027057647705078\n",
            "Steps : 517, Episodic_return : 9.28191089630127\n",
            "Steps : 530, Episodic_return : 8.296965599060059\n",
            "Steps : 547, Episodic_return : 11.44029712677002\n",
            "Steps : 562, Episodic_return : 12.085186958312988\n",
            "Steps : 571, Episodic_return : 2.30056095123291\n",
            "Steps : 584, Episodic_return : 4.5931782722473145\n",
            "Steps : 599, Episodic_return : 10.843355178833008\n",
            "Steps : 614, Episodic_return : 9.9427490234375\n",
            "Steps : 629, Episodic_return : 9.120001792907715\n",
            "Steps : 644, Episodic_return : 11.004743576049805\n",
            "Steps : 658, Episodic_return : 7.705646514892578\n",
            "Steps : 672, Episodic_return : 9.827901840209961\n",
            "Steps : 686, Episodic_return : 8.95318603515625\n",
            "Steps : 700, Episodic_return : 9.475544929504395\n",
            "Steps : 713, Episodic_return : 6.918035507202148\n",
            "Steps : 728, Episodic_return : 10.6209716796875\n",
            "Steps : 741, Episodic_return : 7.583405494689941\n",
            "Steps : 755, Episodic_return : 8.218061447143555\n",
            "Steps : 770, Episodic_return : 10.574761390686035\n",
            "Steps : 786, Episodic_return : 6.212072372436523\n",
            "Steps : 800, Episodic_return : 10.783149719238281\n",
            "Steps : 815, Episodic_return : 10.036881446838379\n",
            "Steps : 831, Episodic_return : 13.68613338470459\n",
            "Steps : 844, Episodic_return : 8.081816673278809\n",
            "Steps : 857, Episodic_return : 8.263201713562012\n",
            "Steps : 870, Episodic_return : 9.18130874633789\n",
            "Steps : 884, Episodic_return : 10.520402908325195\n",
            "Steps : 897, Episodic_return : 4.721587181091309\n",
            "Steps : 906, Episodic_return : -0.5642027854919434\n",
            "Steps : 919, Episodic_return : 7.589604377746582\n",
            "Steps : 933, Episodic_return : 8.432336807250977\n",
            "Steps : 947, Episodic_return : 10.602694511413574\n",
            "Steps : 962, Episodic_return : 9.746108055114746\n",
            "Steps : 976, Episodic_return : 10.621113777160645\n",
            "Steps : 990, Episodic_return : 9.728230476379395\n",
            "Steps : 1003, Episodic_return : 9.060836791992188\n",
            "Steps : 1021, Episodic_return : 11.31247615814209\n",
            "Steps : 1034, Episodic_return : 8.090384483337402\n",
            "Steps : 1048, Episodic_return : 8.663405418395996\n",
            "Steps : 1063, Episodic_return : 9.519807815551758\n",
            "Steps : 1077, Episodic_return : 8.489256858825684\n",
            "Steps : 1084, Episodic_return : -0.0942738875746727\n",
            "Steps : 1097, Episodic_return : 2.5904922485351562\n",
            "Steps : 1108, Episodic_return : 5.141792297363281\n",
            "Steps : 1123, Episodic_return : 12.253812789916992\n",
            "Steps : 1138, Episodic_return : 10.278892517089844\n",
            "Steps : 1151, Episodic_return : 6.957315921783447\n",
            "Steps : 1164, Episodic_return : 6.008119106292725\n",
            "Steps : 1176, Episodic_return : 7.446920394897461\n",
            "Steps : 1190, Episodic_return : 9.223193168640137\n",
            "Steps : 1195, Episodic_return : -6.953041076660156\n",
            "Steps : 1208, Episodic_return : 8.892777442932129\n",
            "Steps : 1223, Episodic_return : 11.376876831054688\n",
            "Steps : 1236, Episodic_return : 8.49910831451416\n",
            "Steps : 1251, Episodic_return : 11.881953239440918\n",
            "Steps : 1265, Episodic_return : 9.637706756591797\n",
            "Steps : 1279, Episodic_return : 8.648473739624023\n",
            "Steps : 1289, Episodic_return : -3.2273905277252197\n",
            "Steps : 1302, Episodic_return : 7.7584638595581055\n",
            "Steps : 1317, Episodic_return : 10.527129173278809\n",
            "Steps : 1332, Episodic_return : 9.943872451782227\n",
            "Steps : 1338, Episodic_return : -6.44279146194458\n",
            "Steps : 1352, Episodic_return : 7.863213539123535\n",
            "Steps : 1367, Episodic_return : 9.049121856689453\n",
            "Steps : 1380, Episodic_return : 10.084565162658691\n",
            "Steps : 1396, Episodic_return : 11.47481632232666\n",
            "Steps : 1409, Episodic_return : 8.917560577392578\n",
            "Steps : 1425, Episodic_return : 9.700613021850586\n",
            "Steps : 1440, Episodic_return : 9.76115608215332\n",
            "Steps : 1454, Episodic_return : 9.58657455444336\n",
            "Steps : 1468, Episodic_return : 9.901905059814453\n",
            "Steps : 1484, Episodic_return : 10.24217700958252\n",
            "Steps : 1497, Episodic_return : 8.793149948120117\n",
            "Steps : 1512, Episodic_return : 11.269107818603516\n",
            "Steps : 1518, Episodic_return : -7.468849182128906\n",
            "Steps : 1532, Episodic_return : 9.886889457702637\n",
            "Steps : 1539, Episodic_return : -1.4155787229537964\n",
            "Steps : 1558, Episodic_return : 9.176819801330566\n",
            "Steps : 1573, Episodic_return : 10.62886905670166\n",
            "Steps : 1582, Episodic_return : -2.577341079711914\n",
            "Steps : 1596, Episodic_return : 10.035426139831543\n",
            "Steps : 1611, Episodic_return : 8.528229713439941\n",
            "Steps : 1626, Episodic_return : 8.534724235534668\n",
            "Steps : 1642, Episodic_return : 13.21739673614502\n",
            "Steps : 1648, Episodic_return : -2.873983860015869\n",
            "Steps : 1657, Episodic_return : -0.5935754179954529\n",
            "Steps : 1671, Episodic_return : 9.334829330444336\n",
            "Steps : 1686, Episodic_return : 11.372699737548828\n",
            "Steps : 1701, Episodic_return : 11.512334823608398\n",
            "Steps : 1715, Episodic_return : 7.577884674072266\n",
            "Steps : 1733, Episodic_return : 13.929186820983887\n",
            "Steps : 1742, Episodic_return : 2.7741384506225586\n",
            "Steps : 1758, Episodic_return : 10.602228164672852\n",
            "Steps : 1765, Episodic_return : 0.6675313115119934\n",
            "Steps : 1778, Episodic_return : 7.938328266143799\n",
            "Steps : 1792, Episodic_return : 10.20118236541748\n",
            "Steps : 1807, Episodic_return : 8.994595527648926\n",
            "Steps : 1821, Episodic_return : 9.318543434143066\n",
            "Steps : 1834, Episodic_return : 8.444584846496582\n",
            "Steps : 1848, Episodic_return : 10.097928047180176\n",
            "Steps : 1862, Episodic_return : 9.037026405334473\n",
            "Steps : 1877, Episodic_return : 9.132020950317383\n",
            "Steps : 1893, Episodic_return : 7.454026222229004\n",
            "Steps : 1906, Episodic_return : 7.704412460327148\n",
            "Steps : 1920, Episodic_return : 9.220972061157227\n",
            "Steps : 1934, Episodic_return : 9.725838661193848\n",
            "Steps : 1947, Episodic_return : 8.136743545532227\n",
            "Steps : 1962, Episodic_return : 10.20337200164795\n",
            "Steps : 1977, Episodic_return : 10.292736053466797\n",
            "Steps : 1991, Episodic_return : 8.133034706115723\n",
            "Steps : 1997, Episodic_return : -2.1063361167907715\n",
            "Steps : 2012, Episodic_return : 11.091428756713867\n",
            "Steps : 2025, Episodic_return : 9.841625213623047\n",
            "Steps : 2038, Episodic_return : 8.750432014465332\n",
            "Steps : 2053, Episodic_return : 11.18403148651123\n",
            "Steps : 2066, Episodic_return : 8.413216590881348\n",
            "Steps : 2080, Episodic_return : 9.499298095703125\n",
            "Steps : 2095, Episodic_return : 10.409960746765137\n",
            "Steps : 2102, Episodic_return : -9.564266204833984\n",
            "Steps : 2116, Episodic_return : 11.060751914978027\n",
            "Steps : 2131, Episodic_return : 11.397258758544922\n",
            "Steps : 2145, Episodic_return : 10.024795532226562\n",
            "Steps : 2160, Episodic_return : 11.452136039733887\n",
            "Steps : 2173, Episodic_return : 8.102575302124023\n",
            "Steps : 2184, Episodic_return : 9.739333152770996\n",
            "Steps : 2198, Episodic_return : 9.54797649383545\n",
            "Steps : 2212, Episodic_return : 9.8781099319458\n",
            "Steps : 2227, Episodic_return : 11.344292640686035\n",
            "Steps : 2241, Episodic_return : 8.340323448181152\n",
            "Steps : 2255, Episodic_return : 9.74337387084961\n",
            "Steps : 2268, Episodic_return : 9.25523567199707\n",
            "Steps : 2284, Episodic_return : 11.502284049987793\n",
            "Steps : 2291, Episodic_return : -5.093691825866699\n",
            "Steps : 2305, Episodic_return : 9.593338966369629\n",
            "Steps : 2311, Episodic_return : -9.106789588928223\n",
            "Steps : 2324, Episodic_return : 10.386126518249512\n",
            "Steps : 2330, Episodic_return : -0.8819307684898376\n",
            "Steps : 2343, Episodic_return : 8.49330997467041\n",
            "Steps : 2356, Episodic_return : 9.837065696716309\n",
            "Steps : 2363, Episodic_return : 0.044458091259002686\n",
            "Steps : 2379, Episodic_return : 9.522364616394043\n",
            "Steps : 2393, Episodic_return : 10.921382904052734\n",
            "Steps : 2409, Episodic_return : 9.544705390930176\n",
            "Steps : 2423, Episodic_return : 10.167145729064941\n",
            "Steps : 2440, Episodic_return : 8.087635040283203\n",
            "Steps : 2453, Episodic_return : 9.905016899108887\n",
            "Steps : 2465, Episodic_return : -0.37555328011512756\n",
            "Steps : 2473, Episodic_return : -0.036142900586128235\n",
            "Steps : 2479, Episodic_return : 4.042449474334717\n",
            "Steps : 2493, Episodic_return : 9.680893898010254\n",
            "Steps : 2507, Episodic_return : 10.170917510986328\n",
            "Steps : 2521, Episodic_return : 10.289766311645508\n",
            "Steps : 2536, Episodic_return : 8.854394912719727\n",
            "Steps : 2550, Episodic_return : 11.928354263305664\n",
            "Steps : 2566, Episodic_return : 7.506210803985596\n",
            "Steps : 2581, Episodic_return : 9.645039558410645\n",
            "Steps : 2596, Episodic_return : 8.887969970703125\n",
            "Steps : 2609, Episodic_return : 7.982974529266357\n",
            "Steps : 2623, Episodic_return : 9.957046508789062\n",
            "Steps : 2638, Episodic_return : 7.396939277648926\n",
            "Steps : 2645, Episodic_return : -5.067306995391846\n",
            "Steps : 2651, Episodic_return : -4.457169532775879\n",
            "Steps : 2666, Episodic_return : 11.960245132446289\n",
            "Steps : 2682, Episodic_return : 9.358258247375488\n",
            "Steps : 2697, Episodic_return : 10.975549697875977\n",
            "Steps : 2712, Episodic_return : 11.925585746765137\n",
            "Steps : 2720, Episodic_return : -4.501883506774902\n",
            "Steps : 2735, Episodic_return : 8.4307279586792\n",
            "Steps : 2750, Episodic_return : 11.868332862854004\n",
            "Steps : 2763, Episodic_return : 8.49459171295166\n",
            "Steps : 2777, Episodic_return : 9.25337028503418\n",
            "Steps : 2791, Episodic_return : 10.038965225219727\n",
            "Steps : 2805, Episodic_return : 9.614187240600586\n",
            "Steps : 2818, Episodic_return : 5.546207904815674\n",
            "Steps : 2826, Episodic_return : -4.324806213378906\n",
            "Steps : 2841, Episodic_return : 9.867469787597656\n",
            "Steps : 2847, Episodic_return : -2.1442694664001465\n",
            "Steps : 2862, Episodic_return : 10.32729434967041\n",
            "Steps : 2876, Episodic_return : 9.864498138427734\n",
            "Steps : 2890, Episodic_return : 9.58285140991211\n",
            "Steps : 2903, Episodic_return : 9.610986709594727\n",
            "Steps : 2920, Episodic_return : 7.643566608428955\n",
            "Steps : 2934, Episodic_return : 9.229793548583984\n",
            "Steps : 2948, Episodic_return : 9.212896347045898\n",
            "Steps : 2963, Episodic_return : 10.125066757202148\n",
            "Steps : 2980, Episodic_return : 9.950492858886719\n",
            "Steps : 2994, Episodic_return : 9.3734130859375\n",
            "Steps : 3010, Episodic_return : 11.119924545288086\n",
            "Steps : 3024, Episodic_return : 9.656926155090332\n",
            "Steps : 3039, Episodic_return : 11.481773376464844\n",
            "Steps : 3053, Episodic_return : 9.768474578857422\n",
            "Steps : 3069, Episodic_return : 6.508419513702393\n",
            "Steps : 3084, Episodic_return : 9.227388381958008\n",
            "Steps : 3096, Episodic_return : 7.571169853210449\n",
            "Steps : 3111, Episodic_return : 12.27568244934082\n",
            "Steps : 3126, Episodic_return : 10.04141902923584\n",
            "Steps : 3140, Episodic_return : 9.609190940856934\n",
            "Steps : 3149, Episodic_return : -1.3306268453598022\n",
            "Steps : 3161, Episodic_return : 7.231871604919434\n",
            "Steps : 3174, Episodic_return : 8.797331809997559\n",
            "Steps : 3187, Episodic_return : 10.43890380859375\n",
            "Steps : 3205, Episodic_return : 8.630690574645996\n",
            "Steps : 3220, Episodic_return : 9.9462890625\n",
            "Steps : 3235, Episodic_return : 10.948806762695312\n",
            "Steps : 3247, Episodic_return : 6.896541595458984\n",
            "Steps : 3259, Episodic_return : 7.714818954467773\n",
            "Steps : 3273, Episodic_return : 9.76927661895752\n",
            "Steps : 3282, Episodic_return : 8.65353775024414\n",
            "Steps : 3296, Episodic_return : 9.930875778198242\n",
            "Steps : 3309, Episodic_return : 8.667976379394531\n",
            "Steps : 3322, Episodic_return : 8.046111106872559\n",
            "Steps : 3335, Episodic_return : 8.569567680358887\n",
            "Steps : 3350, Episodic_return : 11.688953399658203\n",
            "Steps : 3365, Episodic_return : 9.191959381103516\n",
            "Steps : 3379, Episodic_return : 9.26599407196045\n",
            "Steps : 3393, Episodic_return : 7.349619388580322\n",
            "Steps : 3408, Episodic_return : 7.954644680023193\n",
            "Steps : 3423, Episodic_return : 10.653374671936035\n",
            "Steps : 3435, Episodic_return : 8.600890159606934\n",
            "Steps : 3449, Episodic_return : 8.575773239135742\n",
            "Steps : 3463, Episodic_return : 10.409411430358887\n",
            "Steps : 3476, Episodic_return : 8.91812515258789\n",
            "Steps : 3489, Episodic_return : 8.598579406738281\n",
            "Steps : 3497, Episodic_return : 6.619786739349365\n",
            "Steps : 3513, Episodic_return : 9.827207565307617\n",
            "Steps : 3527, Episodic_return : 10.115962028503418\n",
            "Steps : 3534, Episodic_return : 4.207858562469482\n",
            "Steps : 3548, Episodic_return : 10.810797691345215\n",
            "Steps : 3564, Episodic_return : 8.114843368530273\n",
            "Steps : 3579, Episodic_return : 9.368609428405762\n",
            "Steps : 3593, Episodic_return : 10.691784858703613\n",
            "Steps : 3608, Episodic_return : 8.452991485595703\n",
            "Steps : 3615, Episodic_return : 0.006819375790655613\n",
            "Steps : 3626, Episodic_return : 2.656151056289673\n",
            "Steps : 3640, Episodic_return : 10.088218688964844\n",
            "Steps : 3653, Episodic_return : 8.692486763000488\n",
            "Steps : 3669, Episodic_return : 11.213424682617188\n",
            "Steps : 3680, Episodic_return : 4.461821556091309\n",
            "Steps : 3695, Episodic_return : 9.591609954833984\n",
            "Steps : 3700, Episodic_return : -3.1570489406585693\n",
            "Steps : 3708, Episodic_return : 12.120607376098633\n",
            "Steps : 3720, Episodic_return : 7.585892677307129\n",
            "Steps : 3729, Episodic_return : -2.7196712493896484\n",
            "Steps : 3736, Episodic_return : 4.021435737609863\n",
            "Steps : 3751, Episodic_return : 7.635446071624756\n",
            "Steps : 3764, Episodic_return : 7.773044109344482\n",
            "Steps : 3778, Episodic_return : 8.663643836975098\n",
            "Steps : 3791, Episodic_return : 9.581448554992676\n",
            "Steps : 3804, Episodic_return : 8.502882957458496\n",
            "Steps : 3818, Episodic_return : 9.496180534362793\n",
            "Steps : 3832, Episodic_return : 8.820853233337402\n",
            "Steps : 3846, Episodic_return : 9.772889137268066\n",
            "Steps : 3860, Episodic_return : 8.6166353225708\n",
            "Steps : 3875, Episodic_return : 8.592381477355957\n",
            "Steps : 3889, Episodic_return : 9.830512046813965\n",
            "Steps : 3904, Episodic_return : 11.941818237304688\n",
            "Steps : 3918, Episodic_return : 11.559221267700195\n",
            "Steps : 3931, Episodic_return : 8.906715393066406\n",
            "Steps : 3943, Episodic_return : 11.11522102355957\n",
            "Steps : 3957, Episodic_return : 9.81789779663086\n",
            "Steps : 3972, Episodic_return : 10.345964431762695\n",
            "Steps : 3986, Episodic_return : 10.456750869750977\n",
            "Steps : 4000, Episodic_return : 8.103873252868652\n",
            "Steps : 4014, Episodic_return : 10.155759811401367\n",
            "Steps : 4030, Episodic_return : 9.297684669494629\n",
            "Steps : 4042, Episodic_return : 8.048057556152344\n",
            "Steps : 4049, Episodic_return : -3.1329288482666016\n",
            "Steps : 4063, Episodic_return : 8.659049034118652\n",
            "Steps : 4078, Episodic_return : 9.212225914001465\n",
            "Steps : 4093, Episodic_return : 10.429121971130371\n",
            "Steps : 4104, Episodic_return : 2.0365777015686035\n",
            "Steps : 4117, Episodic_return : 12.204566955566406\n",
            "Steps : 4132, Episodic_return : 8.821922302246094\n",
            "Steps : 4144, Episodic_return : 3.7012226581573486\n",
            "Steps : 4153, Episodic_return : -7.307795524597168\n",
            "Steps : 4168, Episodic_return : 9.795536041259766\n",
            "Steps : 4183, Episodic_return : 8.816184043884277\n",
            "Steps : 4197, Episodic_return : 10.513665199279785\n",
            "Steps : 4211, Episodic_return : 9.264609336853027\n",
            "Steps : 4226, Episodic_return : 11.248323440551758\n",
            "Steps : 4240, Episodic_return : 11.050491333007812\n",
            "Steps : 4252, Episodic_return : 7.389026641845703\n",
            "Steps : 4265, Episodic_return : 8.896414756774902\n",
            "Steps : 4273, Episodic_return : 0.9483669996261597\n",
            "Steps : 4286, Episodic_return : 10.071185111999512\n",
            "Steps : 4296, Episodic_return : 5.657578468322754\n",
            "Steps : 4311, Episodic_return : 9.256794929504395\n",
            "Steps : 4324, Episodic_return : 9.05722427368164\n",
            "Steps : 4338, Episodic_return : 9.78985595703125\n",
            "Steps : 4352, Episodic_return : 9.590842247009277\n",
            "Steps : 4366, Episodic_return : 8.58777904510498\n",
            "Steps : 4380, Episodic_return : 9.45289421081543\n",
            "Steps : 4386, Episodic_return : 6.059230804443359\n",
            "Steps : 4402, Episodic_return : 10.264004707336426\n",
            "Steps : 4414, Episodic_return : 8.56888198852539\n",
            "Steps : 4427, Episodic_return : 7.974795341491699\n",
            "Steps : 4442, Episodic_return : 9.62617301940918\n",
            "Steps : 4455, Episodic_return : 8.66784954071045\n",
            "Steps : 4462, Episodic_return : 2.4808549880981445\n",
            "Steps : 4478, Episodic_return : 10.597855567932129\n",
            "Steps : 4491, Episodic_return : 8.613128662109375\n",
            "Steps : 4509, Episodic_return : 10.845893859863281\n",
            "Steps : 4523, Episodic_return : 9.85831069946289\n",
            "Steps : 4538, Episodic_return : 9.576849937438965\n",
            "Steps : 4553, Episodic_return : 9.233288764953613\n",
            "Steps : 4566, Episodic_return : 8.298487663269043\n",
            "Steps : 4579, Episodic_return : 8.469402313232422\n",
            "Steps : 4594, Episodic_return : 9.948596954345703\n",
            "Steps : 4609, Episodic_return : 9.854870796203613\n",
            "Steps : 4623, Episodic_return : 9.670469284057617\n",
            "Steps : 4638, Episodic_return : 10.618232727050781\n",
            "Steps : 4652, Episodic_return : 9.717254638671875\n",
            "Steps : 4665, Episodic_return : 9.449736595153809\n",
            "Steps : 4678, Episodic_return : 8.182730674743652\n",
            "Steps : 4684, Episodic_return : 3.1743319034576416\n",
            "Steps : 4698, Episodic_return : 8.994026184082031\n",
            "Steps : 4712, Episodic_return : 9.915019989013672\n",
            "Steps : 4721, Episodic_return : 1.1205981969833374\n",
            "Steps : 4733, Episodic_return : 7.885360240936279\n",
            "Steps : 4747, Episodic_return : 9.413803100585938\n",
            "Steps : 4760, Episodic_return : 9.003530502319336\n",
            "Steps : 4767, Episodic_return : -2.749250888824463\n",
            "Steps : 4781, Episodic_return : 10.577658653259277\n",
            "Steps : 4795, Episodic_return : 9.750326156616211\n",
            "Steps : 4812, Episodic_return : 11.55162239074707\n",
            "Steps : 4825, Episodic_return : 7.514309883117676\n",
            "Steps : 4838, Episodic_return : 8.462416648864746\n",
            "Steps : 4853, Episodic_return : 10.379500389099121\n",
            "Steps : 4866, Episodic_return : 8.059388160705566\n",
            "Steps : 4878, Episodic_return : 8.829439163208008\n",
            "Steps : 4892, Episodic_return : 9.763169288635254\n",
            "Steps : 4905, Episodic_return : 8.595189094543457\n",
            "Steps : 4920, Episodic_return : 10.196167945861816\n",
            "Steps : 4934, Episodic_return : 10.093833923339844\n",
            "Steps : 4948, Episodic_return : 9.634566307067871\n",
            "Steps : 4964, Episodic_return : 8.627117156982422\n",
            "Steps : 4978, Episodic_return : 9.124992370605469\n",
            "Steps : 4992, Episodic_return : 9.83447265625\n",
            "Steps : 5006, Episodic_return : 10.650732040405273\n",
            "Steps : 5019, Episodic_return : 8.73608684539795\n",
            "Steps : 5034, Episodic_return : 10.746466636657715\n",
            "Steps : 5047, Episodic_return : 8.377917289733887\n",
            "Steps : 5061, Episodic_return : 9.370587348937988\n",
            "Steps : 5075, Episodic_return : 9.759648323059082\n",
            "Steps : 5090, Episodic_return : 8.999899864196777\n",
            "Steps : 5105, Episodic_return : 6.6627278327941895\n",
            "Steps : 5120, Episodic_return : 9.257123947143555\n",
            "Steps : 5130, Episodic_return : 7.5061869621276855\n",
            "Steps : 5144, Episodic_return : 10.025362968444824\n",
            "Steps : 5156, Episodic_return : 7.600327491760254\n",
            "Steps : 5171, Episodic_return : 7.515908718109131\n",
            "Steps : 5186, Episodic_return : 10.673806190490723\n",
            "Steps : 5200, Episodic_return : 9.862689018249512\n",
            "Steps : 5214, Episodic_return : 7.321293830871582\n",
            "Steps : 5229, Episodic_return : 9.608806610107422\n",
            "Steps : 5242, Episodic_return : 10.902657508850098\n",
            "Steps : 5258, Episodic_return : 9.494253158569336\n",
            "Steps : 5271, Episodic_return : 8.488385200500488\n",
            "Steps : 5283, Episodic_return : 7.263222694396973\n",
            "Steps : 5294, Episodic_return : -1.8599863052368164\n",
            "Steps : 5309, Episodic_return : 11.249908447265625\n",
            "Steps : 5324, Episodic_return : 5.3070526123046875\n",
            "Steps : 5337, Episodic_return : 8.132490158081055\n",
            "Steps : 5350, Episodic_return : 8.919229507446289\n",
            "Steps : 5363, Episodic_return : 8.84687328338623\n",
            "Steps : 5377, Episodic_return : 9.466382026672363\n",
            "Steps : 5384, Episodic_return : -11.743866920471191\n",
            "Steps : 5400, Episodic_return : 12.005845069885254\n",
            "Steps : 5415, Episodic_return : 9.471467971801758\n",
            "Steps : 5429, Episodic_return : 11.332990646362305\n",
            "Steps : 5443, Episodic_return : 10.10528564453125\n",
            "Steps : 5457, Episodic_return : 9.048735618591309\n",
            "Steps : 5470, Episodic_return : 8.532403945922852\n",
            "Steps : 5485, Episodic_return : 9.785618782043457\n",
            "Steps : 5499, Episodic_return : 9.543783187866211\n",
            "Steps : 5509, Episodic_return : 2.4154913425445557\n",
            "Steps : 5522, Episodic_return : 8.902031898498535\n",
            "Steps : 5535, Episodic_return : 8.912421226501465\n",
            "Steps : 5552, Episodic_return : 8.652827262878418\n",
            "Steps : 5562, Episodic_return : -1.1817314624786377\n",
            "Steps : 5571, Episodic_return : 3.963784694671631\n",
            "Steps : 5585, Episodic_return : 14.723368644714355\n",
            "Steps : 5594, Episodic_return : -7.750683307647705\n",
            "Steps : 5608, Episodic_return : 9.30884838104248\n",
            "Steps : 5621, Episodic_return : 8.993082046508789\n",
            "Steps : 5628, Episodic_return : -0.4432443380355835\n",
            "Steps : 5641, Episodic_return : 8.94965934753418\n",
            "Steps : 5655, Episodic_return : 10.157319068908691\n",
            "Steps : 5662, Episodic_return : -1.254889965057373\n",
            "Steps : 5676, Episodic_return : 6.975278854370117\n",
            "Steps : 5689, Episodic_return : 8.047534942626953\n",
            "Steps : 5704, Episodic_return : 10.572728157043457\n",
            "Steps : 5718, Episodic_return : 8.532925605773926\n",
            "Steps : 5732, Episodic_return : 10.27165699005127\n",
            "Steps : 5746, Episodic_return : 8.765580177307129\n",
            "Steps : 5759, Episodic_return : 1.4110794067382812\n",
            "Steps : 5771, Episodic_return : 7.281728744506836\n",
            "Steps : 5785, Episodic_return : 8.863594055175781\n",
            "Steps : 5800, Episodic_return : 9.073746681213379\n",
            "Steps : 5807, Episodic_return : 2.1197452545166016\n",
            "Steps : 5821, Episodic_return : 9.36937141418457\n",
            "Steps : 5834, Episodic_return : 7.69714879989624\n",
            "Steps : 5848, Episodic_return : 8.418265342712402\n",
            "Steps : 5861, Episodic_return : 8.737671852111816\n",
            "Steps : 5875, Episodic_return : 10.026285171508789\n",
            "Steps : 5889, Episodic_return : 12.071348190307617\n",
            "Steps : 5903, Episodic_return : 10.094461441040039\n",
            "Steps : 5918, Episodic_return : 8.509655952453613\n",
            "Steps : 5936, Episodic_return : 12.015302658081055\n",
            "Steps : 5949, Episodic_return : 7.622555732727051\n",
            "Steps : 5963, Episodic_return : 10.023236274719238\n",
            "Steps : 5977, Episodic_return : 9.550895690917969\n",
            "Steps : 5994, Episodic_return : 11.785571098327637\n",
            "Steps : 6009, Episodic_return : 10.21117877960205\n",
            "Steps : 6023, Episodic_return : 8.960700988769531\n",
            "Steps : 6039, Episodic_return : 10.003188133239746\n",
            "Steps : 6054, Episodic_return : 9.03404426574707\n",
            "Steps : 6068, Episodic_return : 9.061580657958984\n",
            "Steps : 6081, Episodic_return : 7.085772514343262\n",
            "Steps : 6095, Episodic_return : 10.210152626037598\n",
            "Steps : 6109, Episodic_return : 10.256627082824707\n",
            "Steps : 6122, Episodic_return : 8.740836143493652\n",
            "Steps : 6137, Episodic_return : 10.75826358795166\n",
            "Steps : 6149, Episodic_return : 7.188298225402832\n",
            "Steps : 6164, Episodic_return : 8.831722259521484\n",
            "Steps : 6179, Episodic_return : 9.046932220458984\n",
            "Steps : 6193, Episodic_return : 9.715455055236816\n",
            "Steps : 6204, Episodic_return : 1.292561650276184\n",
            "Steps : 6220, Episodic_return : 10.611424446105957\n",
            "Steps : 6234, Episodic_return : 10.14985466003418\n",
            "Steps : 6249, Episodic_return : 10.084712982177734\n",
            "Steps : 6264, Episodic_return : 10.256294250488281\n",
            "Steps : 6278, Episodic_return : 9.938324928283691\n",
            "Steps : 6294, Episodic_return : 10.464749336242676\n",
            "Steps : 6308, Episodic_return : 9.910533905029297\n",
            "Steps : 6317, Episodic_return : 0.14271755516529083\n",
            "Steps : 6323, Episodic_return : 0.3358074426651001\n",
            "Steps : 6337, Episodic_return : 11.244194984436035\n",
            "Steps : 6353, Episodic_return : 9.626299858093262\n",
            "Steps : 6366, Episodic_return : 9.064712524414062\n",
            "Steps : 6380, Episodic_return : 9.079190254211426\n",
            "Steps : 6394, Episodic_return : 9.77983570098877\n",
            "Steps : 6400, Episodic_return : -4.106757164001465\n",
            "Steps : 6414, Episodic_return : 10.00060749053955\n",
            "Steps : 6428, Episodic_return : 10.273934364318848\n",
            "Steps : 6443, Episodic_return : 12.836593627929688\n",
            "Steps : 6457, Episodic_return : 9.297329902648926\n",
            "Steps : 6470, Episodic_return : 7.527970790863037\n",
            "Steps : 6477, Episodic_return : -1.197441577911377\n",
            "Steps : 6491, Episodic_return : 8.71204948425293\n",
            "Steps : 6505, Episodic_return : 8.84294605255127\n",
            "Steps : 6519, Episodic_return : 9.64990234375\n",
            "Steps : 6531, Episodic_return : 10.630340576171875\n",
            "Steps : 6546, Episodic_return : 10.264870643615723\n",
            "Steps : 6559, Episodic_return : 8.872200965881348\n",
            "Steps : 6568, Episodic_return : -3.4198663234710693\n",
            "Steps : 6577, Episodic_return : -9.016609191894531\n",
            "Steps : 6589, Episodic_return : 7.050931930541992\n",
            "Steps : 6604, Episodic_return : 10.839608192443848\n",
            "Steps : 6617, Episodic_return : 8.946005821228027\n",
            "Steps : 6631, Episodic_return : 10.320236206054688\n",
            "Steps : 6645, Episodic_return : 8.972610473632812\n",
            "Steps : 6659, Episodic_return : 9.383318901062012\n",
            "Steps : 6664, Episodic_return : -7.3134236335754395\n",
            "Steps : 6678, Episodic_return : 8.757558822631836\n",
            "Steps : 6693, Episodic_return : 11.947624206542969\n",
            "Steps : 6707, Episodic_return : 8.853636741638184\n",
            "Steps : 6721, Episodic_return : 9.371857643127441\n",
            "Steps : 6737, Episodic_return : 11.735553741455078\n",
            "Steps : 6750, Episodic_return : 8.753225326538086\n",
            "Steps : 6764, Episodic_return : 9.415334701538086\n",
            "Steps : 6779, Episodic_return : 9.078073501586914\n",
            "Steps : 6787, Episodic_return : -7.611211776733398\n",
            "Steps : 6792, Episodic_return : -5.777319431304932\n",
            "Steps : 6807, Episodic_return : 11.517799377441406\n",
            "Steps : 6823, Episodic_return : 9.438236236572266\n",
            "Steps : 6837, Episodic_return : 9.202713966369629\n",
            "Steps : 6843, Episodic_return : -1.6164385080337524\n",
            "Steps : 6853, Episodic_return : -1.7192190885543823\n",
            "Steps : 6866, Episodic_return : 8.793708801269531\n",
            "Steps : 6880, Episodic_return : 10.294922828674316\n",
            "Steps : 6888, Episodic_return : 4.075676441192627\n",
            "Steps : 6902, Episodic_return : 8.203512191772461\n",
            "Steps : 6918, Episodic_return : 12.796796798706055\n",
            "Steps : 6931, Episodic_return : 7.994473457336426\n",
            "Steps : 6946, Episodic_return : 11.752861976623535\n",
            "Steps : 6956, Episodic_return : 3.4446263313293457\n",
            "Steps : 6964, Episodic_return : 6.756528854370117\n",
            "Steps : 6979, Episodic_return : 9.760966300964355\n",
            "Steps : 6996, Episodic_return : 9.408463478088379\n",
            "Steps : 7009, Episodic_return : 3.633342981338501\n",
            "Steps : 7025, Episodic_return : 11.312138557434082\n",
            "Steps : 7040, Episodic_return : 9.524848937988281\n",
            "Steps : 7045, Episodic_return : 2.782209873199463\n",
            "Steps : 7059, Episodic_return : 9.843947410583496\n",
            "Steps : 7072, Episodic_return : 9.717703819274902\n",
            "Steps : 7086, Episodic_return : 9.447258949279785\n",
            "Steps : 7101, Episodic_return : 9.738789558410645\n",
            "Steps : 7114, Episodic_return : 8.664484024047852\n",
            "Steps : 7128, Episodic_return : 8.166882514953613\n",
            "Steps : 7144, Episodic_return : 9.738094329833984\n",
            "Steps : 7158, Episodic_return : 9.759109497070312\n",
            "Steps : 7173, Episodic_return : 9.987547874450684\n",
            "Steps : 7185, Episodic_return : 6.35115909576416\n",
            "Steps : 7199, Episodic_return : 9.33411693572998\n",
            "Steps : 7204, Episodic_return : 5.294184684753418\n",
            "Steps : 7209, Episodic_return : 0.8462359309196472\n",
            "Steps : 7223, Episodic_return : 10.890124320983887\n",
            "Steps : 7237, Episodic_return : 7.0943379402160645\n",
            "Steps : 7246, Episodic_return : -3.4220104217529297\n",
            "Steps : 7261, Episodic_return : 9.362881660461426\n",
            "Steps : 7274, Episodic_return : 8.162142753601074\n",
            "Steps : 7287, Episodic_return : 9.264823913574219\n",
            "Steps : 7304, Episodic_return : 14.478551864624023\n",
            "Steps : 7320, Episodic_return : 9.616724014282227\n",
            "Steps : 7334, Episodic_return : 9.958495140075684\n",
            "Steps : 7348, Episodic_return : 4.8293375968933105\n",
            "Steps : 7360, Episodic_return : 7.539475440979004\n",
            "Steps : 7375, Episodic_return : 10.037992477416992\n",
            "Steps : 7382, Episodic_return : -1.0835871696472168\n",
            "Steps : 7395, Episodic_return : 8.86118221282959\n",
            "Steps : 7401, Episodic_return : -0.27961212396621704\n",
            "Steps : 7410, Episodic_return : 4.97434663772583\n",
            "Steps : 7424, Episodic_return : 10.08346176147461\n",
            "Steps : 7438, Episodic_return : 9.983131408691406\n",
            "Steps : 7452, Episodic_return : 10.167049407958984\n",
            "Steps : 7466, Episodic_return : 9.318785667419434\n",
            "Steps : 7480, Episodic_return : 10.517081260681152\n",
            "Steps : 7495, Episodic_return : 11.966883659362793\n",
            "Steps : 7502, Episodic_return : 3.9603450298309326\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:112: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Steps : 7515, Episodic_return : 9.415523529052734\n",
            "Steps : 7526, Episodic_return : 4.980264663696289\n",
            "Steps : 7534, Episodic_return : 3.022977113723755\n",
            "Steps : 7542, Episodic_return : -0.5268455743789673\n",
            "Steps : 7548, Episodic_return : 1.2100485563278198\n",
            "Steps : 7554, Episodic_return : 1.3697874546051025\n",
            "Steps : 7559, Episodic_return : 0.5700770020484924\n",
            "Steps : 7564, Episodic_return : 0.4993811249732971\n",
            "Steps : 7569, Episodic_return : 1.9129403829574585\n",
            "Steps : 7574, Episodic_return : 1.402332067489624\n",
            "Steps : 7579, Episodic_return : 1.1648997068405151\n",
            "Steps : 7584, Episodic_return : 1.073323130607605\n",
            "Steps : 7589, Episodic_return : 0.5303382873535156\n",
            "Steps : 7594, Episodic_return : 1.4756370782852173\n",
            "Steps : 7599, Episodic_return : 0.3218744397163391\n",
            "Steps : 7603, Episodic_return : 0.7580966353416443\n",
            "Steps : 7608, Episodic_return : 2.109067440032959\n",
            "Steps : 7613, Episodic_return : 0.5156497359275818\n",
            "Steps : 7617, Episodic_return : 1.2134315967559814\n",
            "Steps : 7622, Episodic_return : 0.8888505101203918\n",
            "Steps : 7627, Episodic_return : 1.24977707862854\n",
            "Steps : 7632, Episodic_return : 1.152634859085083\n",
            "Steps : 7637, Episodic_return : 1.7506884336471558\n",
            "Steps : 7642, Episodic_return : 0.6700425148010254\n",
            "Steps : 7646, Episodic_return : 0.6361978650093079\n",
            "Steps : 7651, Episodic_return : 0.5669763088226318\n",
            "Steps : 7656, Episodic_return : 0.5893937945365906\n",
            "Steps : 7660, Episodic_return : -0.20854324102401733\n",
            "Steps : 7664, Episodic_return : 0.5372357368469238\n",
            "Steps : 7669, Episodic_return : -1.5272105932235718\n",
            "Steps : 7674, Episodic_return : 0.26238831877708435\n",
            "Steps : 7678, Episodic_return : 1.0828739404678345\n",
            "Steps : 7683, Episodic_return : -1.676396369934082\n",
            "Steps : 7687, Episodic_return : 0.7210434675216675\n",
            "Steps : 7692, Episodic_return : 0.938994824886322\n",
            "Steps : 7697, Episodic_return : 1.1867878437042236\n",
            "Steps : 7701, Episodic_return : 0.7661682367324829\n",
            "Steps : 7706, Episodic_return : 1.0468904972076416\n",
            "Steps : 7710, Episodic_return : 0.717494547367096\n",
            "Steps : 7714, Episodic_return : 0.7758974432945251\n",
            "Steps : 7719, Episodic_return : -0.6063098311424255\n",
            "Steps : 7723, Episodic_return : 1.0073541402816772\n",
            "Steps : 7728, Episodic_return : 0.2490793764591217\n",
            "Steps : 7732, Episodic_return : -4.043590545654297\n",
            "Steps : 7736, Episodic_return : 0.4497879147529602\n",
            "Steps : 7740, Episodic_return : 0.6664855480194092\n",
            "Steps : 7744, Episodic_return : 0.6078317165374756\n",
            "Steps : 7748, Episodic_return : 0.87727290391922\n",
            "Steps : 7752, Episodic_return : 0.5052526593208313\n",
            "Steps : 7757, Episodic_return : 0.5380126237869263\n",
            "Steps : 7762, Episodic_return : -0.13714656233787537\n",
            "Steps : 7767, Episodic_return : 1.474643349647522\n",
            "Steps : 7771, Episodic_return : 0.7541983723640442\n",
            "Steps : 7776, Episodic_return : 1.122667908668518\n",
            "Steps : 7781, Episodic_return : 0.7016210556030273\n",
            "Steps : 7786, Episodic_return : -1.6247276067733765\n",
            "Steps : 7790, Episodic_return : 0.7321597337722778\n",
            "Steps : 7794, Episodic_return : 0.7127867937088013\n",
            "Steps : 7799, Episodic_return : 0.9965595602989197\n",
            "Steps : 7803, Episodic_return : 0.7820584774017334\n",
            "Steps : 7807, Episodic_return : 0.5389464497566223\n",
            "Steps : 7812, Episodic_return : 0.8360466957092285\n",
            "Steps : 7816, Episodic_return : 0.44366174936294556\n",
            "Steps : 7821, Episodic_return : 0.958497166633606\n",
            "Steps : 7826, Episodic_return : 0.4277806878089905\n",
            "Steps : 7831, Episodic_return : 0.8858604431152344\n",
            "Steps : 7836, Episodic_return : 1.0664780139923096\n",
            "Steps : 7840, Episodic_return : 0.6510536670684814\n",
            "Steps : 7844, Episodic_return : 0.03333984315395355\n",
            "Steps : 7848, Episodic_return : 0.6703931093215942\n",
            "Steps : 7853, Episodic_return : -0.5871975421905518\n",
            "Steps : 7857, Episodic_return : 1.0272560119628906\n",
            "Steps : 7861, Episodic_return : 0.18852998316287994\n",
            "Steps : 7865, Episodic_return : 1.0063378810882568\n",
            "Steps : 7870, Episodic_return : 0.8629432916641235\n",
            "Steps : 7874, Episodic_return : 0.5347728729248047\n",
            "Steps : 7878, Episodic_return : 0.520427405834198\n",
            "Steps : 7882, Episodic_return : 0.775336742401123\n",
            "Steps : 7887, Episodic_return : 0.14547458291053772\n",
            "Steps : 7892, Episodic_return : 0.369559645652771\n",
            "Steps : 7897, Episodic_return : 0.28249797224998474\n",
            "Steps : 7902, Episodic_return : 0.7922342419624329\n",
            "Steps : 7907, Episodic_return : 0.5383885502815247\n",
            "Steps : 7912, Episodic_return : 0.11585640907287598\n",
            "Steps : 7917, Episodic_return : 0.7860580682754517\n",
            "Steps : 7921, Episodic_return : 0.7773206233978271\n",
            "Steps : 7926, Episodic_return : 1.1675745248794556\n",
            "Steps : 7930, Episodic_return : 0.8325600624084473\n",
            "Steps : 7934, Episodic_return : 0.9232197999954224\n",
            "Steps : 7939, Episodic_return : -0.5324154496192932\n",
            "Steps : 7943, Episodic_return : 0.7211635708808899\n",
            "Steps : 7948, Episodic_return : -3.0068798065185547\n",
            "Steps : 7953, Episodic_return : 0.06940687447786331\n",
            "Steps : 7958, Episodic_return : 0.15376511216163635\n",
            "Steps : 7963, Episodic_return : -0.3826982378959656\n",
            "Steps : 7967, Episodic_return : 0.9249966144561768\n",
            "Steps : 7971, Episodic_return : 0.7453750967979431\n",
            "Steps : 7975, Episodic_return : -5.435912609100342\n",
            "Steps : 7979, Episodic_return : 0.5869054794311523\n",
            "Steps : 7984, Episodic_return : 1.3201215267181396\n",
            "Steps : 7989, Episodic_return : 0.6338974833488464\n",
            "Steps : 7994, Episodic_return : 0.8279597759246826\n",
            "Steps : 7998, Episodic_return : 0.8441863656044006\n",
            "Steps : 8002, Episodic_return : -2.4322309494018555\n",
            "Steps : 8007, Episodic_return : 0.14934685826301575\n",
            "Steps : 8011, Episodic_return : 0.6074281334877014\n",
            "Steps : 8015, Episodic_return : 0.5963385105133057\n",
            "Steps : 8019, Episodic_return : 0.5952854752540588\n",
            "Steps : 8023, Episodic_return : 0.876855731010437\n",
            "Steps : 8027, Episodic_return : 2.1379613876342773\n",
            "Steps : 8032, Episodic_return : 0.24894848465919495\n",
            "Steps : 8037, Episodic_return : 0.9559837579727173\n",
            "Steps : 8041, Episodic_return : 0.7907359600067139\n",
            "Steps : 8046, Episodic_return : 1.2702665328979492\n",
            "Steps : 8051, Episodic_return : 1.0253111124038696\n",
            "Steps : 8055, Episodic_return : 0.8831557035446167\n",
            "Steps : 8059, Episodic_return : 0.7171819806098938\n",
            "Steps : 8064, Episodic_return : 1.0270442962646484\n",
            "Steps : 8069, Episodic_return : 0.12709832191467285\n",
            "Steps : 8074, Episodic_return : -0.07100962102413177\n",
            "Steps : 8078, Episodic_return : -0.5036142468452454\n",
            "Steps : 8083, Episodic_return : 0.8755348920822144\n",
            "Steps : 8088, Episodic_return : 0.228095144033432\n",
            "Steps : 8092, Episodic_return : 0.5897603034973145\n",
            "Steps : 8096, Episodic_return : -0.7913705706596375\n",
            "Steps : 8100, Episodic_return : 1.1234310865402222\n",
            "Steps : 8104, Episodic_return : 0.4475262761116028\n",
            "Steps : 8109, Episodic_return : 0.27496328949928284\n",
            "Steps : 8113, Episodic_return : 0.7697198987007141\n",
            "Steps : 8117, Episodic_return : -5.660068988800049\n",
            "Steps : 8122, Episodic_return : 1.2870125770568848\n",
            "Steps : 8126, Episodic_return : 0.4185614585876465\n",
            "Steps : 8131, Episodic_return : -0.4291008710861206\n",
            "Steps : 8135, Episodic_return : 0.5326215028762817\n",
            "Steps : 8139, Episodic_return : 1.199484944343567\n",
            "Steps : 8143, Episodic_return : 0.8483628630638123\n",
            "Steps : 8147, Episodic_return : 1.5528101921081543\n",
            "Steps : 8151, Episodic_return : 0.817366361618042\n",
            "Steps : 8155, Episodic_return : 0.8705688714981079\n",
            "Steps : 8159, Episodic_return : 1.1965110301971436\n",
            "Steps : 8164, Episodic_return : 1.2242376804351807\n",
            "Steps : 8169, Episodic_return : -1.741916537284851\n",
            "Steps : 8174, Episodic_return : 0.6703488826751709\n",
            "Steps : 8179, Episodic_return : -3.8642959594726562\n",
            "Steps : 8183, Episodic_return : 0.5041593313217163\n",
            "Steps : 8187, Episodic_return : -4.55795955657959\n",
            "Steps : 8192, Episodic_return : 0.01256948709487915\n",
            "Steps : 8196, Episodic_return : 0.7864384055137634\n",
            "Steps : 8200, Episodic_return : 0.7508196830749512\n",
            "Steps : 8204, Episodic_return : 0.698194146156311\n",
            "Steps : 8209, Episodic_return : 0.3364364206790924\n",
            "Steps : 8214, Episodic_return : 0.6296418905258179\n",
            "Steps : 8219, Episodic_return : 0.27769914269447327\n",
            "Steps : 8223, Episodic_return : 0.41122785210609436\n",
            "Steps : 8228, Episodic_return : 0.6133573055267334\n",
            "Steps : 8233, Episodic_return : 0.7138238549232483\n",
            "Steps : 8238, Episodic_return : 0.29651665687561035\n",
            "Steps : 8242, Episodic_return : 0.6317156553268433\n",
            "Steps : 8246, Episodic_return : 0.3394398093223572\n",
            "Steps : 8250, Episodic_return : 0.7019035816192627\n",
            "Steps : 8255, Episodic_return : 0.45399367809295654\n",
            "Steps : 8259, Episodic_return : -5.88160514831543\n",
            "Steps : 8263, Episodic_return : 0.7771500945091248\n",
            "Steps : 8267, Episodic_return : -1.1819798946380615\n",
            "Steps : 8272, Episodic_return : -3.809950351715088\n",
            "Steps : 8276, Episodic_return : 0.7173389792442322\n",
            "Steps : 8281, Episodic_return : 0.6001618504524231\n",
            "Steps : 8285, Episodic_return : -0.30630195140838623\n",
            "Steps : 8289, Episodic_return : 0.6528173685073853\n",
            "Steps : 8294, Episodic_return : 0.6935460567474365\n",
            "Steps : 8299, Episodic_return : 1.2422415018081665\n",
            "Steps : 8304, Episodic_return : -0.106382817029953\n",
            "Steps : 8308, Episodic_return : 0.49650838971138\n",
            "Steps : 8313, Episodic_return : 0.9126425981521606\n",
            "Steps : 8317, Episodic_return : 0.48978570103645325\n",
            "Steps : 8321, Episodic_return : 0.8893601298332214\n",
            "Steps : 8325, Episodic_return : 0.7003949880599976\n",
            "Steps : 8330, Episodic_return : 0.15755131840705872\n",
            "Steps : 8335, Episodic_return : -2.25191068649292\n",
            "Steps : 8339, Episodic_return : 0.7484903335571289\n",
            "Steps : 8344, Episodic_return : 0.9918724298477173\n",
            "Steps : 8348, Episodic_return : -0.4233090877532959\n",
            "Steps : 8352, Episodic_return : -6.212824821472168\n",
            "Steps : 8356, Episodic_return : 0.5961408019065857\n",
            "Steps : 8361, Episodic_return : 0.5821501016616821\n",
            "Steps : 8365, Episodic_return : 0.9305908679962158\n",
            "Steps : 8370, Episodic_return : 1.5693402290344238\n",
            "Steps : 8374, Episodic_return : 0.5385058522224426\n",
            "Steps : 8378, Episodic_return : 1.8360435962677002\n",
            "Steps : 8383, Episodic_return : -1.4505971670150757\n",
            "Steps : 8387, Episodic_return : 0.8294771909713745\n",
            "Steps : 8392, Episodic_return : 1.2922261953353882\n",
            "Steps : 8397, Episodic_return : -0.2702310085296631\n",
            "Steps : 8401, Episodic_return : 0.6503772735595703\n",
            "Steps : 8406, Episodic_return : 0.8532206416130066\n",
            "Steps : 8411, Episodic_return : 0.7881075143814087\n",
            "Steps : 8416, Episodic_return : -2.8542332649230957\n",
            "Steps : 8421, Episodic_return : 0.8711564540863037\n",
            "Steps : 8425, Episodic_return : 0.3443198800086975\n",
            "Steps : 8429, Episodic_return : 0.5623763203620911\n",
            "Steps : 8434, Episodic_return : 0.005483090877532959\n",
            "Steps : 8439, Episodic_return : 0.6995241641998291\n",
            "Steps : 8443, Episodic_return : 0.35499268770217896\n",
            "Steps : 8447, Episodic_return : 0.6407905220985413\n",
            "Steps : 8452, Episodic_return : 1.3093974590301514\n",
            "Steps : 8457, Episodic_return : 1.1660969257354736\n",
            "Steps : 8462, Episodic_return : 0.8664732575416565\n",
            "Steps : 8467, Episodic_return : 0.6326426267623901\n",
            "Steps : 8471, Episodic_return : -3.31501841545105\n",
            "Steps : 8476, Episodic_return : -0.12973077595233917\n",
            "Steps : 8481, Episodic_return : 1.653969168663025\n",
            "Steps : 8486, Episodic_return : 0.7611871957778931\n",
            "Steps : 8491, Episodic_return : 0.6945273876190186\n",
            "Steps : 8495, Episodic_return : 0.9775519371032715\n",
            "Steps : 8500, Episodic_return : -0.4118901491165161\n",
            "Steps : 8504, Episodic_return : -6.079519271850586\n",
            "Steps : 8508, Episodic_return : -2.855319023132324\n",
            "Steps : 8513, Episodic_return : 1.2059258222579956\n",
            "Steps : 8517, Episodic_return : 0.8036799430847168\n",
            "Steps : 8521, Episodic_return : 0.5208145380020142\n",
            "Steps : 8526, Episodic_return : 1.0119470357894897\n",
            "Steps : 8530, Episodic_return : 0.2505408227443695\n",
            "Steps : 8534, Episodic_return : -0.024008184671401978\n",
            "Steps : 8538, Episodic_return : 2.8637871742248535\n",
            "Steps : 8543, Episodic_return : 0.38066762685775757\n",
            "Steps : 8547, Episodic_return : -7.411489963531494\n",
            "Steps : 8551, Episodic_return : -5.749215126037598\n",
            "Steps : 8555, Episodic_return : 0.7017651200294495\n",
            "Steps : 8559, Episodic_return : 0.2773192226886749\n",
            "Steps : 8564, Episodic_return : 0.6445772647857666\n",
            "Steps : 8569, Episodic_return : -1.1989567279815674\n",
            "Steps : 8574, Episodic_return : 0.5661228895187378\n",
            "Steps : 8578, Episodic_return : 0.5536149144172668\n",
            "Steps : 8582, Episodic_return : 0.5553682446479797\n",
            "Steps : 8586, Episodic_return : -0.8829846382141113\n",
            "Steps : 8590, Episodic_return : 0.08784203231334686\n",
            "Steps : 8594, Episodic_return : 0.6694894433021545\n",
            "Steps : 8599, Episodic_return : 0.08451208472251892\n",
            "Steps : 8604, Episodic_return : 1.2975106239318848\n",
            "Steps : 8609, Episodic_return : 0.9931729435920715\n",
            "Steps : 8613, Episodic_return : 1.0067344903945923\n",
            "Steps : 8618, Episodic_return : 0.5140578746795654\n",
            "Steps : 8623, Episodic_return : 1.0728143453598022\n",
            "Steps : 8628, Episodic_return : 1.1009453535079956\n",
            "Steps : 8632, Episodic_return : -5.734134674072266\n",
            "Steps : 8637, Episodic_return : 0.41272854804992676\n",
            "Steps : 8641, Episodic_return : 0.6813518404960632\n",
            "Steps : 8645, Episodic_return : -2.9572744369506836\n",
            "Steps : 8649, Episodic_return : 0.6338978409767151\n",
            "Steps : 8653, Episodic_return : 0.28674906492233276\n",
            "Steps : 8658, Episodic_return : -0.24382032454013824\n",
            "Steps : 8663, Episodic_return : 0.10780444741249084\n",
            "Steps : 8668, Episodic_return : 1.4024181365966797\n",
            "Steps : 8672, Episodic_return : 0.9299942851066589\n",
            "Steps : 8677, Episodic_return : 0.18889737129211426\n",
            "Steps : 8682, Episodic_return : 0.9126819372177124\n",
            "Steps : 8686, Episodic_return : 0.4165852665901184\n",
            "Steps : 8691, Episodic_return : 0.11670166254043579\n",
            "Steps : 8695, Episodic_return : 0.841390073299408\n",
            "Steps : 8699, Episodic_return : 0.6816274523735046\n",
            "Steps : 8703, Episodic_return : -1.130932331085205\n",
            "Steps : 8707, Episodic_return : 0.6550304293632507\n",
            "Steps : 8711, Episodic_return : -3.3563790321350098\n",
            "Steps : 8715, Episodic_return : 0.6872106790542603\n",
            "Steps : 8719, Episodic_return : 0.6003885865211487\n",
            "Steps : 8724, Episodic_return : 0.5662824511528015\n",
            "Steps : 8729, Episodic_return : 0.19103986024856567\n",
            "Steps : 8734, Episodic_return : 0.2837710976600647\n",
            "Steps : 8739, Episodic_return : 1.2463303804397583\n",
            "Steps : 8744, Episodic_return : 0.1746366024017334\n",
            "Steps : 8749, Episodic_return : 0.8144844770431519\n",
            "Steps : 8754, Episodic_return : 1.0796012878417969\n",
            "Steps : 8758, Episodic_return : 0.4390028715133667\n",
            "Steps : 8763, Episodic_return : 0.8673403263092041\n",
            "Steps : 8767, Episodic_return : 0.6615238785743713\n",
            "Steps : 8772, Episodic_return : 1.3795884847640991\n",
            "Steps : 8777, Episodic_return : 0.58302903175354\n",
            "Steps : 8782, Episodic_return : 1.0241122245788574\n",
            "Steps : 8786, Episodic_return : 0.9445001482963562\n",
            "Steps : 8790, Episodic_return : -2.1996405124664307\n",
            "Steps : 8795, Episodic_return : 0.19679659605026245\n",
            "Steps : 8800, Episodic_return : 0.20753800868988037\n",
            "Steps : 8805, Episodic_return : 0.44685012102127075\n",
            "Steps : 8810, Episodic_return : 1.149580955505371\n",
            "Steps : 8815, Episodic_return : 0.9728808403015137\n",
            "Steps : 8819, Episodic_return : 0.6602720618247986\n",
            "Steps : 8824, Episodic_return : 0.7732864618301392\n",
            "Steps : 8829, Episodic_return : 0.8494794964790344\n",
            "Steps : 8833, Episodic_return : 0.842331051826477\n",
            "Steps : 8838, Episodic_return : 0.230677992105484\n",
            "Steps : 8843, Episodic_return : 0.66511070728302\n",
            "Steps : 8847, Episodic_return : -1.4847867488861084\n",
            "Steps : 8851, Episodic_return : -0.38600656390190125\n",
            "Steps : 8856, Episodic_return : 1.3447356224060059\n",
            "Steps : 8861, Episodic_return : 1.2833647727966309\n",
            "Steps : 8865, Episodic_return : 0.8044092059135437\n",
            "Steps : 8869, Episodic_return : -5.217830181121826\n",
            "Steps : 8874, Episodic_return : -0.15645214915275574\n",
            "Steps : 8879, Episodic_return : 0.8677401542663574\n",
            "Steps : 8884, Episodic_return : 0.6723931431770325\n",
            "Steps : 8888, Episodic_return : 0.01779019832611084\n",
            "Steps : 8893, Episodic_return : 1.936719536781311\n",
            "Steps : 8898, Episodic_return : -2.2115681171417236\n",
            "Steps : 8903, Episodic_return : 1.0114442110061646\n",
            "Steps : 8907, Episodic_return : 0.7620909810066223\n",
            "Steps : 8912, Episodic_return : 0.9732522368431091\n",
            "Steps : 8916, Episodic_return : 0.6212152242660522\n",
            "Steps : 8921, Episodic_return : 0.5077306032180786\n",
            "Steps : 8925, Episodic_return : -0.33646339178085327\n",
            "Steps : 8930, Episodic_return : -2.9370508193969727\n",
            "Steps : 8935, Episodic_return : 1.1102794408798218\n",
            "Steps : 8939, Episodic_return : 0.3440694808959961\n",
            "Steps : 8944, Episodic_return : 0.4378819465637207\n",
            "Steps : 8948, Episodic_return : 0.00993010401725769\n",
            "Steps : 8953, Episodic_return : 1.8356746435165405\n",
            "Steps : 8958, Episodic_return : 0.6214685440063477\n",
            "Steps : 8963, Episodic_return : 1.5532864332199097\n",
            "Steps : 8967, Episodic_return : 0.923306941986084\n",
            "Steps : 8971, Episodic_return : -3.6215109825134277\n",
            "Steps : 8976, Episodic_return : 1.417385458946228\n",
            "Steps : 8980, Episodic_return : 0.5873034000396729\n",
            "Steps : 8984, Episodic_return : 1.3565444946289062\n",
            "Steps : 8989, Episodic_return : 0.9918071031570435\n",
            "Steps : 8993, Episodic_return : -4.679698944091797\n",
            "Steps : 8998, Episodic_return : 0.4651740491390228\n",
            "Steps : 9002, Episodic_return : 0.8999007344245911\n",
            "Steps : 9007, Episodic_return : 1.2177904844284058\n",
            "Steps : 9011, Episodic_return : -0.7297450304031372\n",
            "Steps : 9016, Episodic_return : 0.4267578721046448\n",
            "Steps : 9021, Episodic_return : 0.6779612898826599\n",
            "Steps : 9026, Episodic_return : 0.743628740310669\n",
            "Steps : 9030, Episodic_return : 0.5851715207099915\n",
            "Steps : 9035, Episodic_return : 1.1729652881622314\n",
            "Steps : 9040, Episodic_return : 0.9331350326538086\n",
            "Steps : 9044, Episodic_return : -0.6780309677124023\n",
            "Steps : 9049, Episodic_return : 0.35625290870666504\n",
            "Steps : 9053, Episodic_return : 0.2793007791042328\n",
            "Steps : 9058, Episodic_return : 0.6046590805053711\n",
            "Steps : 9062, Episodic_return : 0.5937976241111755\n",
            "Steps : 9066, Episodic_return : -3.6363391876220703\n",
            "Steps : 9070, Episodic_return : 0.700441300868988\n",
            "Steps : 9074, Episodic_return : 1.5243241786956787\n",
            "Steps : 9078, Episodic_return : 0.693274736404419\n",
            "Steps : 9083, Episodic_return : 3.397453784942627\n",
            "Steps : 9088, Episodic_return : 1.0243650674819946\n",
            "Steps : 9092, Episodic_return : -4.622847557067871\n",
            "Steps : 9097, Episodic_return : -0.10326173901557922\n",
            "Steps : 9101, Episodic_return : -0.2711312174797058\n",
            "Steps : 9106, Episodic_return : 0.23032733798027039\n",
            "Steps : 9110, Episodic_return : 0.7613934874534607\n",
            "Steps : 9114, Episodic_return : 0.4866476058959961\n",
            "Steps : 9118, Episodic_return : 0.8924626111984253\n",
            "Steps : 9122, Episodic_return : -2.9009835720062256\n",
            "Steps : 9127, Episodic_return : 0.8701400756835938\n",
            "Steps : 9132, Episodic_return : -0.6620793342590332\n",
            "Steps : 9136, Episodic_return : 0.574049174785614\n",
            "Steps : 9141, Episodic_return : 0.8333110809326172\n",
            "Steps : 9145, Episodic_return : 0.43977242708206177\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcDhjmbUvHeo"
      },
      "source": [
        "}def plot_rewards(rewards, plot_seperate=True , clip=int(1e6), title='unnamed'):\n",
        "    smooth = 5000\n",
        "    \n",
        "    colors = ['red', 'blue', 'green', 'm', 'k', 'y', '#999999']\n",
        "    \n",
        "    plt.figure(figsize=(16,6), dpi=200)\n",
        "    if(plot_seperate):\n",
        "        for k, v in rewards.items():\n",
        "            for t, r in zip(v[0], v[1]):\n",
        "                plt.plot(t, r, label=k)\n",
        "        plt.legend(), plt.show()\n",
        "        return\n",
        "    \n",
        "    for j, (k, v) in enumerate(rewards.items()):\n",
        "        r_vec = np.zeros((len(v[0]), clip-smooth+1))\n",
        "        for i, (t, r) in enumerate(zip(v[0], v[1])):\n",
        "            r_vec[i,:] = convolve(np.interp(np.arange(clip), t, r), smooth)\n",
        "    \n",
        "        mean = np.mean(np.array(r_vec), axis=0)\n",
        "        std = np.std(np.array(r_vec), axis=0)\n",
        "        plt.plot(mean, label=k, color=colors[j])\n",
        "        plt.fill_between(np.arange(0, len(mean)), mean+std, mean-std, facecolor=colors[j], alpha=0.3)\n",
        "    \n",
        "    plt.xlabel('timesteps'), plt.ylabel('episodic returns')\n",
        "    plt.title(title)\n",
        "    plt.legend(loc='lower right'), plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}